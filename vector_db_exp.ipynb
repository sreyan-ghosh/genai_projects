{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector DB Experimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will try to leverage the Cohere Embeddings generator to create our embeddings and then use Pinecone to store the vectors before using the Cohere API again to create a QA on a PDF file that we have chosen to be our source data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain.llms import Cohere\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from ApiSecrets import ApiSecrets\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a PDF Directory as our Retrieval Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"pdfs\")\n",
    "source_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "text_chunks = text_splitter.split_documents(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\n",
      "sentence. We give two such examples above, from two different heads from the encoder self-attention\n",
      "at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(text_chunks[-1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings and Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "os.environ[\"COHERE_API_KEY\"] = ApiSecrets.COHERE_API_KEY\n",
    "os.environ[\"PINECONE_API_KEY\"] = ApiSecrets.PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
    "text = \"this is a test document\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index_name = \"testing-vec-db\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Embeddings from each chunk from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as LC_Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Pinecone', 'CohereEmbeddings'], vectorstore=<langchain_community.vectorstores.pinecone.Pinecone object at 0x000001EA664117F0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecstore = LC_Pinecone.from_texts([chunk.page_content for chunk in text_chunks], embeddings, index_name=index_name)\n",
    "vecstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
      "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
      " Score: 0.599198282\n"
     ]
    }
   ],
   "source": [
    "simi_prompt = \"what is attention?\"\n",
    "simi_result = vecstore.similarity_search_with_score(simi_prompt)\n",
    "print(f\"Answer: {simi_result[0][0].page_content}\\n Score: {simi_result[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Retrieval QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Cohere(cohere_api_key = os.getenv(\"COHERE_API_KEY\"))\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vecstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attention is a mechanism that helps an AI model focus on different parts of data while doing training.  It is a way to model the dependency of one part of the data on another part, or self-dependencies. It is very useful for large NLP models so they can understand the context of a sentence since each sentence consists of ordered words. \n"
     ]
    }
   ],
   "source": [
    "qa_prompt = \"what is attention?\"\n",
    "qa_result = qa.run(qa_prompt)\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to quit\n",
      "Ans:  From the provided context, a Transformer is a model architecture that substitutes recurrence and self-attention mechanisms for drawing global dependencies between input and output. Specifically, The Transformer presents an updated approach to sequence transduction models that utilize multi-headed self-attention mechanisms, replacing the use of recurrent layers in encoder-decoder architectures. The model allows for more parallelization and can reach a new state of the art in translation tasks. \n",
      "Ans:  This paper was presented at the 31st Conference on Neural Information Processing Systems (NIPS 2017) and was published on August 2, 2023, as stated in the copyright section of the paper. \n",
      "The authors' names and affiliations are listed on the paper, and the identity of the specific author who wrote the paper may be included in this information in some cases. \n",
      "However, I don't have access to real-time data on the internet, so I cannot search for any subsequent updates to the paper or any later annotations. \n",
      "\n",
      "If you provide me with the names of the authors, I can tell you whether they are included in the aforementioned list that is provided in the paper. \n",
      "\n",
      "Can I assist you with anything else? \n",
      "Ans:  The provided text describes the premise of the attention paper as focusing on presenting a variety of attention mechanisms and arguing for the usefulness of self-attention in sequence transduction tasks. \n",
      "They describe a multitude of attention types, including intra-attention or self-attention, describing relations between positions in a single sequence. This mechanism allows the model to pay attention to different representation subspaces at different positions, giving it the ability to follow long-distance dependencies, as shown in Figure 3. \n",
      "The paper supports the argument for the usefulness of attention in sequence transduction tasks, used successfully in reading comprehension, abstractive summarization, textual entailment, and learning task-independent sentence representations, etc. \n",
      "\n",
      "Let me know if you'd like any clarification on the provided text or if there are any other questions I can help with! \n"
     ]
    }
   ],
   "source": [
    "print(\"Type 'exit' to quit\")\n",
    "while True:\n",
    "    user_input = input(\"Enter Prompt: \")\n",
    "    if user_input == \"exit\" or user_input == \"Exit\":\n",
    "        break\n",
    "    if user_input == '':\n",
    "        continue\n",
    "    res = qa({\"query\": user_input})\n",
    "    print(f\"Ans: {res[\"result\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings and ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
